const fs = require('fs');
const path = require('path');
const { Pool } = require('pg');
const dotenv = require('dotenv');

dotenv.config();

// Create a new pool specifically for migrations
const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
});

async function runMigrations() {
  const client = await pool.connect();
  
  try {
    console.log('ğŸ”„ Starting database migration...');
    console.log('ğŸ“Š Environment:', process.env.NODE_ENV || 'development');
    console.log('ğŸ”— Database URL:', process.env.DATABASE_URL ? 'âœ“ Set' : 'âœ— Not set');
    
    // Test connection
    try {
      const testResult = await client.query('SELECT NOW() as now, version() as version');
      console.log('âœ… Database connection successful!');
      console.log('â° Server time:', testResult.rows[0].now);
    } catch (error) {
      console.error('âŒ Database connection failed:', error.message);
      throw error;
    }
    
    // Start transaction
    await client.query('BEGIN');
    console.log('ğŸ“ Transaction started');
    
    // Read SQL files
    const sqlFiles = [
      { name: 'db.sql', path: path.join(__dirname, '../db.sql') },
      { name: 'db-updates.sql', path: path.join(__dirname, '../db-updates.sql') }
    ];
    
    for (const sqlFile of sqlFiles) {
      console.log(`\nğŸ“„ Processing ${sqlFile.name}...`);
      
      // Check if file exists
      if (!fs.existsSync(sqlFile.path)) {
        console.log(`âš ï¸  ${sqlFile.name} not found, skipping...`);
        continue;
      }
      
      const sql = fs.readFileSync(sqlFile.path, 'utf8');
      
      // Parse SQL into statements
      const statements = parseSQLStatements(sql);
      console.log(`ğŸ“‹ Found ${statements.length} SQL statements`);
      
      // Execute each statement
      for (let i = 0; i < statements.length; i++) {
        const statement = statements[i];
        const preview = statement.substring(0, 80).replace(/\s+/g, ' ');
        
        try {
          console.log(`  [${i + 1}/${statements.length}] ${preview}${statement.length > 80 ? '...' : ''}`);
          await client.query(statement);
          console.log(`  âœ“ Success`);
        } catch (error) {
          // Handle "already exists" errors gracefully
          if (
            error.message.includes('already exists') ||
            error.message.includes('duplicate') ||
            error.code === '42P07' || // relation already exists
            error.code === '42710'    // object already exists
          ) {
            console.log(`  â„¹ï¸  Already exists (skipping)`);
          } else {
            console.error(`  âœ— Error:`, error.message);
            throw error;
          }
        }
      }
      
      console.log(`âœ… ${sqlFile.name} completed`);
    }
    
    // Commit transaction
    await client.query('COMMIT');
    console.log('âœ… Transaction committed');
    
    // Verify tables were created
    const result = await client.query(`
      SELECT 
        table_name,
        (SELECT COUNT(*) FROM information_schema.columns WHERE table_schema = 'public' AND columns.table_name = tables.table_name) as column_count
      FROM information_schema.tables 
      WHERE table_schema = 'public'
      ORDER BY table_name;
    `);
    
    console.log('\nğŸ“‹ Database Tables:');
    console.log('â”€'.repeat(50));
    result.rows.forEach(row => {
      console.log(`  âœ“ ${row.table_name.padEnd(30)} (${row.column_count} columns)`);
    });
    console.log('â”€'.repeat(50));
    console.log(`  Total: ${result.rows.length} tables`);
    
    console.log('\nğŸ‰ Migration completed successfully!');
    
  } catch (error) {
    // Rollback on error
    try {
      await client.query('ROLLBACK');
      console.log('â†©ï¸  Transaction rolled back');
    } catch (rollbackError) {
      console.error('âŒ Rollback failed:', rollbackError.message);
    }
    
    console.error('\nğŸ’¥ Migration failed!');
    console.error('Error:', error.message);
    if (process.env.NODE_ENV === 'development') {
      console.error('Stack:', error.stack);
    }
    throw error;
    
  } finally {
    client.release();
    await pool.end();
  }
}

/**
 * Parse SQL file into individual statements
 * Handles comments and multi-line statements
 */
function parseSQLStatements(sql) {
  const lines = sql.split('\n');
  let currentStatement = '';
  const statements = [];
  let inBlockComment = false;
  
  for (const line of lines) {
    let processedLine = line.trim();
    
    // Handle block comments /* */
    if (processedLine.includes('/*')) {
      inBlockComment = true;
    }
    if (inBlockComment) {
      if (processedLine.includes('*/')) {
        inBlockComment = false;
      }
      continue;
    }
    
    // Skip empty lines and single-line comments
    if (!processedLine || processedLine.startsWith('--')) {
      continue;
    }
    
    // Remove inline comments
    const commentIndex = processedLine.indexOf('--');
    if (commentIndex !== -1) {
      processedLine = processedLine.substring(0, commentIndex).trim();
    }
    
    if (!processedLine) continue;
    
    // Add to current statement
    currentStatement += processedLine + '\n';
    
    // Check if statement is complete (ends with semicolon)
    if (processedLine.endsWith(';')) {
      const statement = currentStatement.trim();
      if (statement && statement !== ';') {
        statements.push(statement);
      }
      currentStatement = '';
    }
  }
  
  // Add any remaining statement
  if (currentStatement.trim() && currentStatement.trim() !== ';') {
    statements.push(currentStatement.trim());
  }
  
  return statements;
}

// Run migrations
runMigrations()
  .then(() => {
    console.log('\nâœ¨ All done!');
    process.exit(0);
  })
  .catch((error) => {
    console.error('\nâŒ Migration script failed');
    process.exit(1);
  });
